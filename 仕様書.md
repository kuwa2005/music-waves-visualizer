# Music Waves Visualizer 仕様書

## 1. 概要

Music Waves Visualizerは、画像と音楽ファイルを読み込んで、音楽に合わせた音声波形を可視化した動画を作成するWebアプリケーションです。

### 1.1 主な機能

- **画像ファイルの読み込み**: 背景画像として使用（ドラッグ&ドロップ対応）
- **音楽ファイルの読み込み**: 音声波形の分析対象（MP4ファイルにも対応）
- **リアルタイム波形可視化**: 7つの表示モードで音声波形を可視化
- **解像度選択**: 1920×1080、1080×1920、1920×1920から選択可能
- **表示調整機能**: 各モードごとに倍率・位置を調整可能
- **プレビュー機能**: 音楽を再生しながら波形をリアルタイム表示
- **動画生成機能**: 音声と波形を動画として録画し、MP4形式で出力

### 1.2 デモサイト

https://music-waves-visualizer.vercel.app/

## 2. 技術スタック

### 2.1 フロントエンド

- **フレームワーク**: Next.js 13.1.2
- **言語**: TypeScript 4.6.2
- **UIライブラリ**: Material-UI (MUI) 5.11.4
- **スタイリング**: SCSS

### 2.2 主要ライブラリ

- **@ffmpeg/ffmpeg**: 0.10.1 - 動画変換処理（WebAssembly版）
- **@emotion/react/styled**: 11.10.5 - CSS-in-JS
- **@mui/icons-material**: 5.11.0 - アイコンコンポーネント

### 2.3 ブラウザAPI

- **Web Audio API**: 音声解析と再生
  - `AudioContext`
  - `AnalyserNode`
  - `AudioBuffer`
  - `MediaStreamAudioDestinationNode`
- **Canvas API**: 波形描画と画像表示
- **MediaRecorder API**: 動画録画
- **requestAnimationFrame**: アニメーション処理

## 3. 機能詳細

### 3.1 ファイル読み込み

#### 3.1.1 画像ファイル読み込み

- **対応形式**: `image/*`（すべての画像形式）、MP4（静止画として最初のフレームを抽出）
- **読み込み方法**:
  - ドラッグ&ドロップ: 複数ファイルをドロップすると自動判定
  - ボタンから選択: 「画像ファイルを選ぶ」ボタンから選択
- **処理内容**:
  - ファイル選択後、`Image`オブジェクトまたは`HTMLVideoElement`として読み込み
  - 選択したCanvasサイズに合わせて自動リサイズ
  - アスペクト比を維持しつつ、中央配置
  - キャンバス上に背景として描画

#### 3.1.2 音楽ファイル読み込み

- **対応形式**: `audio/*`（すべての音声形式）、MP4（音声トラックを抽出）
- **読み込み方法**:
  - ドラッグ&ドロップ: 複数ファイルをドロップすると自動判定（MP4はデフォルトで音楽として扱う）
  - ボタンから選択: 「音楽ファイルを選ぶ」ボタンから選択
- **処理内容**:
  - 通常の音声ファイル: `ArrayBuffer`として読み込み → `AudioContext.decodeAudioData()`でデコード → `AudioBuffer`として保存
  - MP4ファイル: `HTMLVideoElement`を使用して`MediaElementAudioSourceNode`で音声を抽出
  - プレビュー・録画ボタンを有効化

### 3.2 波形可視化モード

7つの表示モードを選択可能：

#### モード0: 周波数バー（Frequency Bars）

- **データ取得**: `analyser.getByteFrequencyData()` - 周波数スペクトルデータ
- **表示方法**: 128本の縦バーを横に並べて表示
- **動作**: 各周波数帯域の強度をバーの高さで表現
- **色**: 白色（rgba(255, 255, 255, 0.8)）

#### モード1: 折れ線（Waveform）

- **データ取得**: `analyser.getByteTimeDomainData()` - 波形データ
- **表示方法**: 時系列データを折れ線グラフで表示
- **動作**: 音声の実際の波形をリアルタイムで描画
- **色**: 白色のストローク（rgba(255, 255, 255, 0.8)）

#### モード2: 円形（Circular）

- **データ取得**: `analyser.getByteFrequencyData()` - 周波数スペクトルデータ
- **表示方法**: 円形に配置された256本のバー
- **動作**: 
  - 低音（1Hz）の強度に基づいて中心からの距離を調整
  - 各周波数を円周上に配置して回転表示
- **色**: 白色（rgba(255, 255, 255, 0.8)）

#### モード3: 上下対称バー（Symmetrical Bars）

- **データ取得**: `analyser.getByteFrequencyData()` - 周波数スペクトルデータ
- **表示方法**: 中央から上下に広がるカラフルなバー
- **動作**: 周波数に応じた色分けで上下対称に表示
- **色**: 周波数に応じたグラデーション

#### モード4: ドット表示（Dot Display）

- **データ取得**: `analyser.getByteFrequencyData()` - 周波数スペクトルデータ
- **表示方法**: 32×16のドットマトリクス表示
- **動作**: 周波数データをドットマトリクスに変換して表示
- **色**: 強度に応じた色変化

#### モード5: 波形（上下対称）（Symmetrical Waveform）

- **データ取得**: `analyser.getByteTimeDomainData()` - 波形データ
- **表示方法**: 波形を上下対称に表示
- **動作**: 中央線を基準に上下に波形を描画
- **色**: 白色のストローク（rgba(255, 255, 255, 0.8)）

#### モード6: 3D風バー（3D Bars）

- **データ取得**: `analyser.getByteFrequencyData()` - 周波数スペクトルデータ
- **表示方法**: 奥行きのある3D風バー
- **動作**: パースペクティブ効果で3D風に表示
- **色**: 奥行きに応じた色変化

### 3.3 Canvasサイズ選択

3つの解像度から選択可能：

- **1920×1080** (16:9): 一般的な動画サイズ（横長）
- **1080×1920** (9:16): 縦型動画用（縦長）
- **1920×1920** (1:1): 正方形動画用

各解像度に対応してCanvasサイズが動的に変更されます。

### 3.4 表示調整機能

各モードごとに以下のパラメータを調整可能：

- **横幅倍率（scaleX）**: 0.1〜3.0（デフォルト: 1.0）
- **縦幅倍率（scaleY）**: 0.1〜3.0（デフォルト: 1.0）
- **横位置（offsetX）**: -150%〜150%（Canvasサイズに対するパーセンテージ、デフォルト: 0%）
- **縦位置（offsetY）**: -150%〜150%（Canvasサイズに対するパーセンテージ、デフォルト: 0%）

調整値は開発者モードで自動保存・読み込みが可能です。

### 3.5 プレビュー機能

- **動作**:
  1. `AudioBufferSourceNode`または`HTMLVideoElement`から音声を取得
  2. `AnalyserNode`とスピーカー出力、`MediaStreamAudioDestinationNode`に接続
  3. 音声再生を開始
  4. `requestAnimationFrame`でリアルタイム波形描画（調整パラメータを適用）
- **停止**: 再生中に再度ボタンをクリックすると停止

### 3.6 動画生成機能

- **録画プロセス**:
  1. Canvasのストリームと音声ストリームを結合
  2. `MediaRecorder`でWebM形式（H.264コーデック）で録画開始
  3. 音楽再生を自動開始
  4. 音楽終了時に録画停止
- **変換プロセス**:
  1. 録画されたWebMデータをBlobとして取得
  2. FFmpeg（WebAssembly版）でMP4形式に変換
  3. 変換完了後、自動ダウンロード
- **ファイル名**: `movie_[ランダム8文字].mp4`
- **録画サイズ**: 選択したCanvasサイズ（プレビュー表示サイズとは無関係）

### 3.7 UIコンポーネント

#### ボタン

- **画像ファイルを選ぶ**: 画像ファイル選択ダイアログを開く（ドロップゾーン内に配置）
- **音楽ファイルを選ぶ**: 音声ファイル選択ダイアログを開く（ドロップゾーン内に配置）
- **スペクトラムアナライザー選択**: 7つのモードからボタンで選択
- **解像度選択**: 3つの解像度からボタンで選択（「16:9 1920×1080」「9:16 1080×1920」「1:1 1920×1920」）
- **プレビュー**: 音楽再生と波形表示の開始/停止（音楽読み込み後有効化）
- **動画を生成**: 録画開始（音楽読み込み後、再生中以外で有効化）

#### 表示調整UI（アコーディオン）

- **横幅倍率スライダー**: 0.1〜3.0
- **縦幅倍率スライダー**: 0.1〜3.0
- **横位置スライダー**: -150%〜150%（パーセンテージと実ピクセル値を表示）
- **縦位置スライダー**: -150%〜150%（パーセンテージと実ピクセル値を表示）

#### 開発者モードUI（オプション）

- **設定のエクスポート**: すべての保存された設定をJSON形式でクリップボードにコピー
- **設定のインポート**: JSONを貼り付けて設定を復元
- **設定のクリア**: すべての保存された設定を削除

#### 通知（Snackbar）

- **表示タイミング**:
  - 画像読み込み完了
  - 音楽読み込み完了
  - 録画開始
  - MP4変換中
  - 変換完了
  - エラー発生時

#### ファイル名表示

- **画像ファイル名**: 「画像ファイルを選ぶ」ボタンの横に表示
- **音楽ファイル名**: 「音楽ファイルを選ぶ」ボタンの横に表示

## 4. アーキテクチャ

### 4.1 ファイル構成

```
music-waves-visualizer/
├── pages/
│   ├── _app.tsx          # アプリケーション全体設定（GA、メタタグ）
│   └── index.tsx          # メインページ（UIと状態管理）
├── components/
│   └── CustomSnackbar.tsx # 通知コンポーネント
├── lib/
│   ├── Canvas.ts          # Canvas描画ロジック
│   ├── Ffmpeg.ts          # FFmpeg動画変換処理
│   └── Gtag.tsx           # Google Analytics設定
├── styles/
│   ├── globals.scss       # グローバルスタイル
│   └── Home.module.scss   # ホームページスタイル
└── public/                # 静的ファイル
```

### 4.2 主要な処理フロー

#### 4.2.1 初期化

1. `AudioContext`の作成
2. `AnalyserNode`の設定（FFTサイズ: 2048）
3. `MediaStreamAudioDestinationNode`の作成（録画用）
4. Canvasの初期化

#### 4.2.2 画像読み込みフロー

```
ファイル選択 → Imageオブジェクト作成 → onload → Canvas描画開始
```

#### 4.2.3 音楽読み込みフロー

```
ファイル選択 → ArrayBuffer読み込み → decodeAudioData → AudioBuffer保存 → ボタン有効化
```

#### 4.2.4 プレビューフロー

```
ボタンクリック → AudioBufferSourceNode作成 → 接続 → 再生開始 → アニメーションループ開始
```

#### 4.2.5 録画フロー

```
ボタンクリック → ストリーム結合 → MediaRecorder作成 → 録画開始 → 音楽再生 → 
音楽終了 → 録画停止 → WebM → FFmpeg → MP4 → ダウンロード
```

### 4.3 状態管理

React Hooksを使用したローカル状態管理：

- `useState`: UI状態（再生中、ボタン有効/無効、モード選択、通知）
- `useRef`: 永続的な参照（AudioContext、Canvas、AudioBuffer、ノード参照）
- `useEffect`: 副作用処理（初期化、アニメーションループ）

## 5. 技術的な詳細

### 5.1 Canvas設定

- **サイズ**: 1920×1080、1080×1920、1920×1920から選択（動的に変更可能）
- **背景色**: 黒色（rgba(34, 34, 34, 1.0)）
- **更新頻度**: `requestAnimationFrame`による60fps相当
- **GPU加速**: `canvas.getContext("2d", { alpha: false, desynchronized: true, willReadFrequently: false })`で有効化
- **プレビュー表示**: CSSで最大480px幅（9:16の場合は240px）に縮小表示（録画サイズには影響なし）

### 5.2 Audio API設定

- **FFTサイズ**: 2048（周波数バッファ: 1024）
- **サンプリングレート**: 音声ファイルに依存
- **接続構成**:
  ```
  AudioBufferSourceNode
    ├── AnalyserNode (波形分析)
    ├── AudioDestinationNode (スピーカー出力)
    └── MediaStreamAudioDestinationNode (録画用)
  ```

### 5.3 録画設定

- **録画形式**: WebM（H.264コーデック）
- **変換形式**: MP4
- **FFmpegコマンド**: `-i input.webm -vcodec copy output.mp4`
- **FFmpegバージョン**: 0.10.0（WebAssembly版）

### 5.4 セキュリティ設定

`next.config.js`で以下のHTTPヘッダーを設定：

- `Cross-Origin-Opener-Policy: same-origin`
- `Cross-Origin-Embedder-Policy: require-corp`

これにより、SharedArrayBufferなどの機能を使用可能にします。

### 5.5 ブラウザ互換性

- **対応ブラウザ**: Chrome、Firefox、Edge（最新版）
- **未確認**: iOS Safari、Android Chrome
- **注意事項**: 
  - 離脱ガード機能あり（`beforeunload`イベント）
  - ブラウザのプレフィックス対応（`webkit`、`moz`）

## 6. 制限事項・注意事項

### 6.1 制限事項

1. **モバイル対応**: iOS、Androidは動作未確認
2. **ファイルサイズ**: 大きな音楽ファイルや画像ファイルは処理に時間がかかる可能性
3. **メモリ**: 長時間の音楽や高解像度画像はメモリ消費が大きい
4. **録画時間**: 音楽の長さに依存（録画時間 = 音楽の長さ）

### 6.2 注意事項

1. **録画中の操作**: 録画中は他の操作を控えること
2. **ブラウザタブ**: 録画中はブラウザタブを閉じないこと（離脱ガードあり）
3. **変換時間**: MP4変換には時間がかかる場合がある（ブラウザコンソールでログ確認可能）

## 7. 今後の拡張可能性

- 波形の色・スタイルカスタマイズ
- 追加の可視化モード
- 動画品質設定（解像度、ビットレート）
- 複数画像の切り替え機能
- エフェクト機能（フィルター、アニメーション）

## 8. 開発者モード

環境変数 `NEXT_PUBLIC_DEVELOPER_MODE=true` を設定すると、以下の機能が利用可能：

- 各モード×解像度の組み合わせごとに設定を自動保存
- 設定のエクスポート/インポート
- 設定のクリア

詳細は [DEVELOPER_MODE.md](./DEVELOPER_MODE.md) を参照してください。

## 9. 開発者情報

- **元作者**: komura-c
- **改変版作者**: PCM8 (kuwa2005)
- **元リポジトリ**: https://github.com/komura-c/music-waves-visualizer
- **改変版リポジトリ**: https://github.com/kuwa2005/music-waves-visualizer
- **元記事**: [オーディオ波形動画を生成するWebぺージの作り方](https://tech-blog.voicy.jp/entry/2022/12/11/235929)

