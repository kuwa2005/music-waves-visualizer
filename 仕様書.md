# Music Waves Visualizer 仕様書

## 1. 概要

Music Waves Visualizerは、画像と音楽ファイルを読み込んで、音楽に合わせた音声波形を可視化した動画を作成するWebアプリケーションです。

### 1.1 主な機能

- **画像ファイルの読み込み**: 背景画像として使用
- **音楽ファイルの読み込み**: 音声波形の分析対象
- **リアルタイム波形可視化**: 3つの表示モードで音声波形を可視化
- **プレビュー機能**: 音楽を再生しながら波形をリアルタイム表示
- **動画録画機能**: 音声と波形を動画として録画し、MP4形式で出力

### 1.2 デモサイト

https://music-waves-visualizer.vercel.app/

## 2. 技術スタック

### 2.1 フロントエンド

- **フレームワーク**: Next.js 13.1.2
- **言語**: TypeScript 4.6.2
- **UIライブラリ**: Material-UI (MUI) 5.11.4
- **スタイリング**: SCSS

### 2.2 主要ライブラリ

- **@ffmpeg/ffmpeg**: 0.10.1 - 動画変換処理（WebAssembly版）
- **@emotion/react/styled**: 11.10.5 - CSS-in-JS
- **@mui/icons-material**: 5.11.0 - アイコンコンポーネント

### 2.3 ブラウザAPI

- **Web Audio API**: 音声解析と再生
  - `AudioContext`
  - `AnalyserNode`
  - `AudioBuffer`
  - `MediaStreamAudioDestinationNode`
- **Canvas API**: 波形描画と画像表示
- **MediaRecorder API**: 動画録画
- **requestAnimationFrame**: アニメーション処理

## 3. 機能詳細

### 3.1 ファイル読み込み

#### 3.1.1 画像ファイル読み込み

- **対応形式**: `image/*`（すべての画像形式）
- **処理内容**:
  - ファイル選択後、`Image`オブジェクトとして読み込み
  - Canvasサイズ（1024×512）に合わせて自動リサイズ
  - アスペクト比を維持しつつ、中央配置
  - キャンバス上に背景として描画

#### 3.1.2 音楽ファイル読み込み

- **対応形式**: `audio/*`（すべての音声形式）
- **処理内容**:
  - ファイルを`ArrayBuffer`として読み込み
  - `AudioContext.decodeAudioData()`でデコード
  - `AudioBuffer`として保存
  - プレビュー・録画ボタンを有効化

### 3.2 波形可視化モード

3つの表示モードを選択可能：

#### モード0: 周波数バー（Frequency Bars）

- **データ取得**: `analyser.getByteFrequencyData()` - 周波数スペクトルデータ
- **表示方法**: 128本の縦バーを横に並べて表示
- **動作**: 各周波数帯域の強度をバーの高さで表現
- **色**: 白色（rgba(255, 255, 255, 0.8)）

#### モード1: 折れ線（Waveform）

- **データ取得**: `analyser.getByteTimeDomainData()` - 波形データ
- **表示方法**: 時系列データを折れ線グラフで表示
- **動作**: 音声の実際の波形をリアルタイムで描画
- **色**: 白色のストローク（rgba(255, 255, 255, 0.8)）

#### モード2: 円形（Circular）

- **データ取得**: `analyser.getByteFrequencyData()` - 周波数スペクトルデータ
- **表示方法**: 円形に配置された256本のバー
- **動作**: 
  - 低音（1Hz）の強度に基づいて中心からの距離を調整
  - 各周波数を円周上に配置して回転表示
- **色**: 白色（rgba(255, 255, 255, 0.8)）

### 3.3 プレビュー機能

- **動作**:
  1. `AudioBufferSourceNode`を作成し、デコード済み音声を設定
  2. `AnalyserNode`とスピーカー出力、`MediaStreamAudioDestinationNode`に接続
  3. 音声再生を開始
  4. `requestAnimationFrame`でリアルタイム波形描画
- **停止**: 再生中に再度ボタンをクリックすると停止

### 3.4 動画録画機能

- **録画プロセス**:
  1. Canvasのストリームと音声ストリームを結合
  2. `MediaRecorder`でWebM形式（H.264コーデック）で録画開始
  3. 音楽再生を自動開始
  4. 音楽終了時に録画停止
- **変換プロセス**:
  1. 録画されたWebMデータをBlobとして取得
  2. FFmpeg（WebAssembly版）でMP4形式に変換
  3. 変換完了後、自動ダウンロード
- **ファイル名**: `movie_[ランダム8文字].mp4`

### 3.5 UIコンポーネント

#### ボタン

- **画像ファイルを選ぶ**: 画像ファイル選択ダイアログを開く
- **音楽ファイルを選ぶ**: 音声ファイル選択ダイアログを開く
- **プレビュー**: 音楽再生と波形表示の開始/停止（音楽読み込み後有効化）
- **動画を録画**: 録画開始（音楽読み込み後、再生中以外で有効化）

#### セレクトボックス

- **表示モード選択**: 周波数バー / 折れ線 / 円形から選択

#### 通知（Snackbar）

- **表示タイミング**:
  - 画像読み込み完了
  - 音楽読み込み完了
  - 録画開始
  - MP4変換中
  - 変換完了
  - エラー発生時

## 4. アーキテクチャ

### 4.1 ファイル構成

```
music-waves-visualizer/
├── pages/
│   ├── _app.tsx          # アプリケーション全体設定（GA、メタタグ）
│   └── index.tsx          # メインページ（UIと状態管理）
├── components/
│   └── CustomSnackbar.tsx # 通知コンポーネント
├── lib/
│   ├── Canvas.ts          # Canvas描画ロジック
│   ├── Ffmpeg.ts          # FFmpeg動画変換処理
│   └── Gtag.tsx           # Google Analytics設定
├── styles/
│   ├── globals.scss       # グローバルスタイル
│   └── Home.module.scss   # ホームページスタイル
└── public/                # 静的ファイル
```

### 4.2 主要な処理フロー

#### 4.2.1 初期化

1. `AudioContext`の作成
2. `AnalyserNode`の設定（FFTサイズ: 2048）
3. `MediaStreamAudioDestinationNode`の作成（録画用）
4. Canvasの初期化

#### 4.2.2 画像読み込みフロー

```
ファイル選択 → Imageオブジェクト作成 → onload → Canvas描画開始
```

#### 4.2.3 音楽読み込みフロー

```
ファイル選択 → ArrayBuffer読み込み → decodeAudioData → AudioBuffer保存 → ボタン有効化
```

#### 4.2.4 プレビューフロー

```
ボタンクリック → AudioBufferSourceNode作成 → 接続 → 再生開始 → アニメーションループ開始
```

#### 4.2.5 録画フロー

```
ボタンクリック → ストリーム結合 → MediaRecorder作成 → 録画開始 → 音楽再生 → 
音楽終了 → 録画停止 → WebM → FFmpeg → MP4 → ダウンロード
```

### 4.3 状態管理

React Hooksを使用したローカル状態管理：

- `useState`: UI状態（再生中、ボタン有効/無効、モード選択、通知）
- `useRef`: 永続的な参照（AudioContext、Canvas、AudioBuffer、ノード参照）
- `useEffect`: 副作用処理（初期化、アニメーションループ）

## 5. 技術的な詳細

### 5.1 Canvas設定

- **サイズ**: 1024×512ピクセル
- **背景色**: 黒色（rgba(34, 34, 34, 1.0)）
- **更新頻度**: `requestAnimationFrame`による60fps相当

### 5.2 Audio API設定

- **FFTサイズ**: 2048（周波数バッファ: 1024）
- **サンプリングレート**: 音声ファイルに依存
- **接続構成**:
  ```
  AudioBufferSourceNode
    ├── AnalyserNode (波形分析)
    ├── AudioDestinationNode (スピーカー出力)
    └── MediaStreamAudioDestinationNode (録画用)
  ```

### 5.3 録画設定

- **録画形式**: WebM（H.264コーデック）
- **変換形式**: MP4
- **FFmpegコマンド**: `-i input.webm -vcodec copy output.mp4`
- **FFmpegバージョン**: 0.10.0（WebAssembly版）

### 5.4 セキュリティ設定

`next.config.js`で以下のHTTPヘッダーを設定：

- `Cross-Origin-Opener-Policy: same-origin`
- `Cross-Origin-Embedder-Policy: require-corp`

これにより、SharedArrayBufferなどの機能を使用可能にします。

### 5.5 ブラウザ互換性

- **対応ブラウザ**: Chrome、Firefox、Edge（最新版）
- **未確認**: iOS Safari、Android Chrome
- **注意事項**: 
  - 離脱ガード機能あり（`beforeunload`イベント）
  - ブラウザのプレフィックス対応（`webkit`、`moz`）

## 6. 制限事項・注意事項

### 6.1 制限事項

1. **モバイル対応**: iOS、Androidは動作未確認
2. **ファイルサイズ**: 大きな音楽ファイルや画像ファイルは処理に時間がかかる可能性
3. **メモリ**: 長時間の音楽や高解像度画像はメモリ消費が大きい
4. **録画時間**: 音楽の長さに依存（録画時間 = 音楽の長さ）

### 6.2 注意事項

1. **録画中の操作**: 録画中は他の操作を控えること
2. **ブラウザタブ**: 録画中はブラウザタブを閉じないこと（離脱ガードあり）
3. **変換時間**: MP4変換には時間がかかる場合がある（ブラウザコンソールでログ確認可能）

## 7. 今後の拡張可能性

- 波形の色・スタイルカスタマイズ
- 追加の可視化モード
- 動画品質設定（解像度、ビットレート）
- 複数画像の切り替え機能
- エフェクト機能（フィルター、アニメーション）

## 8. 開発者情報

- **作者**: komura-c
- **ライセンス**: 未記載（privateプロジェクト）

